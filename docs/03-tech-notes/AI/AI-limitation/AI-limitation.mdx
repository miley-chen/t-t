---
title: AI 的先天限制
tags: ['2024', ai, note]
keywords: [AI, 人工智慧, 限制]
last_update:
  date: 2024/11/10
---

即使 AI 的發展越來越進步，它依然面臨一些先天性的限制，讓它在實際應用中可能產生誤差或不準確的情況。

無論是將它應用於不同產品上的開發端，還是使用應用相關技術工具的用戶端，瞭解他的限制並培養辨認 AI 提供的哪些內容是真實有效都是必要的。

## AI 的限制：知識截止點、知識飄移、偏誤、幻覺

### 知識截止點（Knowledge cutoff）

知識截止點指的是 AI 的訓練數據僅更新到某一特定時間點之後便不再更新。因此，AI 對於這之後的最新資訊一無所知，無法了解訓練日期後發生的事件。

假設一個 AI 模型的知識截止點為 2023 年 10 月，那麼在 2024 年問這個 AI 當前的世界大事，它可能會回答與現實不符的內容。例如，對於剛發生的選舉結果或科技進展，它可能無法正確回答。

### 知識飄移（Drift）

知識漂移是指 AI 模型的準確性隨著時間下降的現象，這通常是因為 AI 所用的訓練數據已經不再反映當前的真實情況。知識截止點往往是導致知識漂移的原因，因為 AI 無法更新新資訊，自然會隨著時間推移逐漸與當下情境脫節，導致錯誤或不適當的建議，影響其準確性和適用性。

假設一個金融 AI 預測模型在過去的經濟數據上訓練，但由於市場條件隨時間變化，過去的數據可能不再適用於現況，這會導致模型的預測失準。例如，一個房地產價格預測模型若無法考量最新的經濟變動，可能無法正確預測未來的房價。

### 偏誤（Bias）

偏誤是指 AI 在生成結果時，會受到訓練數據中潛在的偏見影響，可能會出現不公正或扭曲的結果。

偏誤可依照產生來源分為以下兩種類型：

### 系統性偏誤（Systemic Bias）

來自社會、組織或制度的偏好，使得 AI 在處理數據時從帶有偏見的訓練數據中學到了特定偏好，並在無意中延續了過去存在的偏見。

假設某公司開發了一個 AI 系統來自動篩選應聘者的履歷，並根據應聘者的背景、經歷和技能進行評分。這個 AI 系統的訓練數據主要來自於公司過去多年的招聘記錄，但這些記錄中包含了長期以來形成的性別偏見——例如，該公司的過往聘用記錄中男性候選人比例較高。在這種情況下，AI 系統可能會不自覺地學習到「男性更適合某些職位」的偏見，從而在篩選過程中自動對女性應聘者打低分，即使她們的資歷、經驗和技能都相當優秀。這樣的系統性偏誤使得 AI 篩選流程中存在不公平的性別歧視，從而影響了女性應聘者的機會。

### 數據偏誤（Data Bias）

由於訓練數據本身存在偏見或錯誤，AI 模型的輸出也因此不準確或有偏向。

例如一個人臉辨識系統的訓練數據主要來自於某個族群的人，比如白人，這個系統可能會對黃種人、黑人等其他族群的辨識較不準確，導致誤判性別或年齡。

### 幻覺（Hallucinations）

幻覺是指 AI 生成的答案看似合理但實際不正確，或是編造出無根據的內容。這種錯誤可能是因為 AI 在訓練數據中找不到直接參考，於是「創造」了內容。幻覺可能會誤導使用者，使他們相信 AI 的錯誤答案，因此在 AI 回答後需進行人為審查，以確保資訊正確。


## 重點整理

- 知識截止點來自 AI 無法獲取最新資訊，是知識的靜態限制

  - 飄移是知識逐漸脫節的動態影響，使 AI 回應的知識不符合現況
  - 幻覺是知識截止點和飄移造成的結果之一，當 AI 無法提供真實答案時，可能為了填補空缺而編造出錯誤的回應

- 偏誤和幻覺都可能來自 AI 訓練數據的品質問題

  - 當數據本身存在偏見或錯誤，AI 就可能在回答中反映這些偏見
  - 偏見可能導致幻覺中的不公平表現，讓 AI 編造出有偏向的答案